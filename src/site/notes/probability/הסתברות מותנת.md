---
dateCreated: "2022-11-05 22:11"
tags: [probability, computer_science]
dg-publish: true
dg-home: false
---


# הסתברות מותנת

הסתברות מותנת מספקת לנו דרך להגיע למסקנות ותוצאות של ניסוי בהתבסס על __מידע חלקי__. הנה כמה דוגמאות שמתארות את הקונספט :
1. בניסוי  שכולל בתוכו שתי הטלות רצופות של קובייה, סכום שתי ההטלות הוא $9$ . מה הסבירות שההטלה הראשונה הייתה 6?
2. במשחק ניחוש שמות,  האות הראשונה היא $t$ של המילה שנוחשה. מה הסבירות שהאות השנייה היא $h$ ?
3. בהינתן שתוצאות הבדיקה הינן שליליות מה הסיכוי של בן אדם להיות נגוע במחלה מסויימת?

באופן מדוייק יותר, בהינתן ניסוי, מרחב מדגם מתאים וחוקי הסתברות, ממחל שאנחנו יודעים שהתוצאה שלנו היא בתוך מאורע מסויים $B$. אנחנו מעוניינים לכמת את הסבירות שהתוצאה שלנו שייכת גם למאורע אחר $A$. לפיכך, אנחנו מעוניינים לבנות חוק הסתברות חדש שלוקח בחשבון את המידע שיש ברשותנו: חוק הסתברות כך שלכל מאורע $A$, מתאר את __ההסתברות המותנת__ של $A$ __בהינתן__ $B$.
הסימון של זה הוא $P(A|B)$.
נרצה שהחוק הזה יהווה חוק הסתברות לגיטימי שמקיים את האקסיומות. ההסתברות המותנית צריכה להיות עקבית עם האינטואציה ההסתברותית שלנו.

בסופו של דבר אנחנו נקבל את הטענה הבאה:
$$P(A|B)= \frac{P(A\cap B)}{P(B)}$$
הנחת היסוד היא ש $P(B)>0$ . אם להיות ספציפיים יותר אז $P(A|B)\geq 0\rightarrow P(B)> 0$
כלומר ההסתברות המותנת היא החלק היחסי של החיתוך בין שתי ההסתברויות להסתברות שאנחנו מניחים שקרתה. 

## פירוט ההסתברות המותנת כחוק הסתברות 
* אי שליליות- קל מאוד מההגדרה לראות זאת כיוון שמדובר בשבר של איברים חיוביים
* נורמליזציה-
$$P(\Omega | B)= \frac{P(\Omega\cap B)}{P(B)}= \frac{P(B)}{P(B)}=1 $$
* אדטיביות- בהינתן $A_{1},A_{2}$  מאורעות זרים:
$$\displaylines{
P(A_{1}\cup A_{2}| B)= \frac{P((A_{1}\cup A_{2})\cap B)}{P(B)}= \frac{P((A_{1}\cap B)\cup (A_{2}\cup B))}{P(B)}\\ = \frac{P(A_{1}\cup B)+ P(A_{2}\cup B)}{P(B)}= \frac{P(A_{1}\cup B)}{P(B)}+\frac{P(A_{2}\cup B)}{P(B)} = P(A_{1}| B)+ P(A_{2}| B)
}$$
_המעבר השלישי נובע בגלל שאם המאורעות זרים אז גם החיתוך שלהם עם $B$ זר אחד לשני._

כמובן שמהנ״ל נובע שבהנתן קבוצות לא זרות אז 
$$P(A\cup C | B)\leq P(A|B)+ P(C|B)$$
וכמובן גם ש 
$$P(B|B)=1$$
### תכונות נוספות של הסתברות מותנת
1) ניתן להסתכל על הסתברות מותנת גם כחוק הסתברות על ״יקום חדש״ $B$, בגלל שכל ההסתברות המותנת מרוכזת סביבו.
2) אם אנחנו במרחב שווה הסתברות בדיד 
$$P(A|B)= \frac{|A\cap B|}{|B|}$$

3) $$P(A|B)= 1- P(A^{c}|B)$$
נוכיח זאת 
$$\frac{P(A\cap B)}{P(B)}+ \frac{P(A^{c}\cap B)}{P(B)}= \frac{P(A\cap B)+ P(A^{c}\cap B)}{P(B)}$$
במונה יש שתי מאורעות זרים כי $A,A^{c}$ מאורעות זרים ולכן 
$$\frac{P([A\cap B]\cup [A^{c}\cap B])}{P(B)}= \frac{P(B\cap (A\cup A^{c}))}{P(B)}= \frac{P(B\cap \Omega)}{P(B)}= \frac{P(B)}{P(B)}=1 $$


## דוגמאות להסתברות מותנת
1) נזרוק מטבע הוגן שלוש פעמים רצופות. ברצוננו למצוא את ההסתברות $P(A|B)$ בהינתן 
$$A=\{\text{more heads than tails}\}\ \ B=\{\text{first toss is a head}\}$$
מרחב המדגם ייראה ככה: 
$$\Omega = \{HHH,HHT,HTH,HTT,THH,THT,TTH,TTT\}$$
בגלל שמדובר במרחב שווה הסתברות בדיד יתקיים 
$$P(B)= \frac{4}{8}$$
המאורע $A\cap B$ יכיל בתוכו את שלושת האלמנטים $HHH,HHT,HTH$ ולכן ההסתברות היא
$$P(A\cap B)= \frac{3}{8}$$

וההסתברות המותנת לפי הנוסחה היא 
$$P(A|B)=\frac{\frac{3}{8}}{\frac{4}{8}}= \frac{3}{4}$$
יכלנו גם לחלק פשוט את העוצמות כי זה מרחב שווה הסתברות.

2) נגלגל פעמיים  קובייה הוגנת עם 4 צדדים (מרחב שווה הסתברות). נסמן $X,Y$ כתוצאות ההטלה הראשונה והשנייה בהתאמה ונרצה למצוא את $P(A|B)$ בהינתן 
 $$A=\{max(X,Y)=m\}, B=\{min(X,Y)=2\}$$
m יכול להיות כל אחד מהערכים.
נרצה להעריך את הסתברות החיתוך של המאורעות ושל $B$. בגלל שזה מרחב שווה הסתברות נוכל פשוט לחלק בין העוצמות למשל עבור m=2 נקבל מרחב מדגם כזה 
![[Pasted image 20221106003323.png|350]]
בכל מקרה נוכל לשרטט את הנ״ל לכל m ונקבל 
$$P(\{max(X,Y)=m\} \ |\ B)= \begin{cases} \frac{2}{5}& m=3\vee m=4 \\ \frac{1}{5}& m=2 \\ 0& m=1\end{cases}$$
 3) קבוצת עיצוב שמרנית $C$ וקבוצת עיצוב חדשנית $N$ מתבקשים בנפקד לעצב מוצר חדש בתוך חודש. מניסיון עבר אנחנו יודעים ש 
 $$\displaylines{
 \text{(a) The probability that team C is successful is } \frac{2}{3}\\
 \text{(b) The probability that team N is successful is } \frac{1}{2} \\ 
 \text{(c) The probability that at least one team is successful is } \frac{3}{4}
 }$$
 בהנחה שבידיוק קבוצה אחת עיצבה את המוצר בהצלחה, מה ההתסברות שזאת הייתה קבוצה $N$?
 מרחב המדגם שלנו ייראה ככה 
 $$\Omega = \{SS,SF,FF,FS\}$$
 כאשר התו הראשון מייצג את ההצלחה או כשלון של קבוצה $C$ והשני את של קבוצה $N$ . וכמובן שלכל אחת יש שתי מצבים $\{S,F\}$ (אלו מאורעות של מרחב מדגם אחר שלא קשורות באופן ישיר למרחב המדגם שלנו).
אנחנו יודעים את הנתונים הבאים 
$$\displaylines{
P(SS)+P(SF)= \frac{2}{3},\  \ P(SS)+P(FS)= \frac{1}{2}, \  \ P(SS)+P(SF)+P(FS)= \frac{3}{4}
}$$

מאקסיומת הנורמליות ומהנתונים הנ״ל נוכל לחלץ את כל ההסתברויות במרחב המדגם 
$$P(SS)= \frac{5}{12},\ \ P(SF)= \frac{1}{4},\ \ P(FS)= \frac{1}{12}, \ \ P(FF)= \frac{1}{4}$$
וסך הכל 
$$P(FS\ |\ \{SF,FS\})=  \frac{\frac{1}{12}}{\frac{1}{4}+ \frac{1}{12}}= \frac{1}{4}$$


## שימוש בהסתברות מותנת לבניית מודל הסתברות 
כשבונים מודל הסתברות לניסוי שיש לו אופי סדרתי, נהוג קודם לכן לתאר את ההסתברויות המותנות ולאחר מכן להשתמש בהם כדי לבנות את ההסתברויות שאינן מותנות.
זאת בגלל החוק $P(A\cap B)= P(B)P(A|B)$ שמשתמע ישירות מהכלל של הסתברות מותנת אבל הוא מאוד שימושי בתהליך הזה.

כדי להדגים את השימוש בהסתברות מותנת נתאר את התרחיש הבא:
__זיהוי רדאר__. אם מטוס קרב נוכח בשמים הרדאר מזהה אותו ומשמיע אזעקה עם הסתברות של 0.99. אם המטוס קרב לא נוכח הרדאר ישמיע אזעקת שווא בהתסברות של 0.1 . ניתן להניח שמטוס הקרב יהיה בשמיים בשהסתברות של 0.05. מהי ההסתברות של מטוס הקרב להיות נוכח ככה שאין אזעקה?
ייצוג סדרתי של הניסוי מתאים כאן, תיכף נראה זאת, נגדיר את המאורעות הבאים 
$$A=\{\text{an aircraft is present}\}, \ \ B=\{\text{the radar generates an alarm}\}$$
נשים לב שיתקיים גם 
$$A^{c}=\{\text{an aircraft is not present}\}, \ \ B^{c}=\{\text{the radar does not generates an alarm}\}$$

נסתכל על התיאור הרציף של הניסוי 
![[Pasted image 20221106140123.png|350]]
כל תוצאה אפשרית היא עלה בעץ וכל הסתברות בעלה שווה לכפל של ההסתברויות שבענפים בדרך אל השורש. נשים לב שהענפים זה ההסתברויות המותנות שנתונות לנו במקרה הזה. 
סך הכל נקבל 
$$\displaylines{
P(A^{c}\cap B)= P(A^{c})P(B|A^{c})= 0.95\cdot 0.10 = 0.095\\
P(A\cap B^{c})= P(A)P(B^{c}| A) = 0.05\cdot 0.01 = 0.0005
}$$
נוכל להכליל את התהליך שעשינו בדוגמה הזאת כדי לחשב הסתברויות בצירוף עם תיאור סדרתי מבוסס עץ של הניסוי:
1) מסדרים את העץ כך שמאורע שאנחנו מעוניינים בו משוייך לעלה. נתבונן בהתרחשוב המאורע כרצף של צעדים, כלומר, התזוזה על הענפים לאורך המסלול מהשורש לעלה.
2) מסמנים את ההסתברות המותנת בכל ענף של העץ.
3) נכפיל את כל נקודות המעבר במסלול מהשורש לעלה וזה ההתסברות של העלה.

במונחים מתמטיים אנחנו מתמודדים עם מאורע $A$ שמתרחש אם ורק אם סדרת האירועים $A_{1},\dots,A_{n}$ התרחשו. כלומר 
$$A=\bigcap_{i=1}^{n}A_{i}$$
זה בא לידי ביטוי כמסלול בעץ מהשורש עד לעלה. 

## חוק הכפל
מההסבר הנ״ל נוכל לנסח את החוק הבא,

בהנחה שכל ההסתברויות המותנות גדולות ממש מ0 אזי :
$$P(\cap_{i=1}^{n} A_{i})= P(A_{1})P(A_{2}| A_{1})P(A_{3}| A_{1}\cap A_{2})\cdots P(A_{n}| \cap_{i-1}^{n-1}A_{i})$$
אם נפתח כל אחד מההסתברויות המותנות נקבל 
$$P(\cap_{i=1}^{n} A_{i})= P(A_{1})\cdot \frac{P(A_{1}\cap A_{2})}{P(A_{1})}\cdots \frac{P(\cap_{i=1}^{n}A_{i})}{P(\cap_{i=1}^{n-1}A_{i})} $$

![[Pasted image 20221106144043.png]]

התמונה מקלה לראות את החוק עבור 2 מאורעות למשל , 
$$P(A_{1}\cap A_{2})= P(A_{1})\cdot P(A_{2}|A_{1})$$


