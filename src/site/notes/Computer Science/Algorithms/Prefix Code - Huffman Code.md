---
{"dateCreated":"2022-11-19 12:23","tags":["algorithms","computer_science"],"pageDirection":"rtl","dg-publish":true,"permalink":"/computer-science/algorithms/prefix-code-huffman-code/","dgPassFrontmatter":true}
---


# Prefix Code - Huffman Code
קודי-הפמן שימושיים מאוד וטכניקה אפיקטיבית לדחיסת מידע , שחוסכת 90% − 20% בד"כ , תלוי במאפייני המידע שצריכים לדחוס . נסתכל על המידע כסדרה של אותיות , האלגוריתם החמדן $Huffman$ משתמש בטבלה של תדיריות עבור כל אות לבנות דרך אופטימלית לייצג את את האותיות כמחרוזת בינארית .

נגדיר __קוד בינארי חוקי__ לא״ב $\Sigma$  כפונקצייה $c:\Sigma\to\{0,1\}^{+}$ כך שהתכונות הבאות מתקיימות 
1) חח״ע $c(\sigma)=c(\sigma^{\prime})\leftrightarrow \sigma=\sigma^{\prime}$
2) שרשור של ביטים יכול לייצר רק שרשור אחד של תווים מהא״ב.

דוגמה טובה לכך היא [[Computer Science/Computer System/ASCII\|ASCII]] שבו כל תו משתמש ב 8 ביטים ולכן יש לכלהיותר $2^{8}$ תווים אפשריים ויש רק דרך אחת לקודד כל תו. באופן כללי, תמיד קיים קוד בינארי לא״ב כלשהו כך שאורך כל קידוד הוא $\lceil\log|\Sigma|\rceil$ .

דוגמה לקוד שלא מקיים את התכונה השנייה היא $0001110001$ עבור הקידוד :

| $\sigma$ | c($\sigma$) |
| -------- | ----------- |
| a        | 0         |
| b        | 01          |
| c        | 11        |
| d        | 1         |

באופן הזה נקבל ש $aaadddaaad$ ו $aabcaab$ יקודדו לאותה מחרוזת בינארית.

## prefix-free code
קוד תחילי עבור $\Sigma$ א״ב הוא פונקצייה $c:\Sigma\rightarrow\{0,1\}^{+}$ כך ש:
1) חח״ע
2) לכל שתי תווים שונים בא״ב יתקיים שהפעלת c על אחד מהם היא לא __רישא__ של השני ולהיפך

| $\sigma$ | c($\sigma$) |
| -------- | ----------- |
| a        | 000         |
| b        | 01          |
| c        | 1111        |
| d        | 001         |
| e        | 1110        |
| f        | 110            |

  _בטבלה הראשונה c(d) הוא רישא של c(c)_ וכאן זה תרחיש שלא יתקיים.

## prefix-free tree
נוכל להתייחס ל prefix-free code  כעץ בינארי באופן הבא:
1) התווים הם עלים
2) הבן השמאלי משוייך ל 0 והימני ל 1 
3) $c(\sigma)$ הוא שרשור של הביטים מהשורש לעלה.

למשל עבור הטבלה למעלה העץ ייראה כך
![Pasted image 20221119161628.png|350](/img/user/Assets/Pasted%20image%2020221119161628.png)

> [!info]
> כמו כן נשים לב שקריאה של מחרוזת בינארית בשיטה הזאת תהיה קריאה של המחרוזת משמאל לימין עד שמגיעים לעלה וזה הופך להיות תו ואז ממשיכים מהתחלה מהשורש כדי להגיע לתו הבא. 

נסמן: $d_{T}(\sigma)$ את העומק של $\sigma$ ב עץ $T$ שמייצג קוד תחיליות $c$ . יתקיים:

$$|c(\sigma)|=d_{T}(\sigma)$$

(הסימון מייצג את מספר האיברים במחרוזת הבינארית)ֿ

## optimal prefix-free code
נניח שיש לנו קובץ מאוד גדול ואנחנו רוצים לקודד את האותיות בקובץ על ידי שימוש ב prefix-free code שמביאה את ההגודל הקובץ המקודד __למינימום__.
נסמן את קבוצת האותיות בקובץ ב $\Sigma$ ונסמן לכל $\sigma\in\Sigma$ את $f_{\sigma}$ שזה מספר הפעמים שהתו מופיע בקובץ.
אם נשתמש בקוד תחילי $c$ עם עץ $T$ אז הגודל הכולל לקובץ אחרי קידוד יהיה :

$$COST(T)= \sum\limits_{\sigma\in\Sigma} f_{\sigma}\cdot |c(\sigma)|= \sum\limits_{\sigma\in\Sigma}f_{\sigma}\cdot d_{T}(\sigma)$$

זה בעצם הסכום של כל התדירות לאות כפול העומק שלה בעץ כלומר כמה פעמים נצטרך לרדת בעץ כדי להגיע לאות הזאת.
נרצה לבנות עץ קוד תחילי אופטימלי שעבורו COST יהיה מינימלי. נשים לב שאנחנו מקבלים כקלט את הא״ב והתדירות של כל תו בא״ב.

השאיפה שלנו היא להגיע למצב שבוא אנחנו בונים __Variable length code__ שזה אומר שנשים קוד קטן יותר לאותיות עם תדירות גבוהה וקוד ארוך לאותיות עם תדירות נמוכה. למשל עבור הקידוד והתדירויות
![Pasted image 20221119182230.png|300](/img/user/Assets/Pasted%20image%2020221119182230.png)
נרצה להגיע למצב הבא
![Pasted image 20221119182301.png|300](/img/user/Assets/Pasted%20image%2020221119182301.png)

השאלה היא איך מגיעים למצב כזה?

__כיוון אינטואיטיבי__ היה למיין את כל התווים לפי התדירות ולכל $\alpha_{i}$ שזה התו בדירוג ה $i$ להגדיר שקוד שלו יהיה $\underbrace{111\dots 1}_{\text{i times}} \ \ 0$  ככה נבטיח שהתו עם הקידוד ה $i$ יהיה בעומק ה $i$ בעץ. עם זאת, זה לא פתרון אופטימלי למשל עבור הקידוד הנ״ל
![Pasted image 20221119182347.png|450](/img/user/Assets/Pasted%20image%2020221119182347.png)
העץ השמאלי הוא הרגיל והעץ הימני הוא האופטמילי וזה בניגוד לאינטואיצייה שתיארתי למעלה שהייתה נותנת עץ אחר.

בשביל שנוכל לבנות את המבנה האופטימלי הזה בצורה פורמלית ולהוכיח את נכונותו כ[[Computer Science/Algorithms/greedy algorithms\|אלגוריתם חמדני]] נרצה להוכיח את הטענה הבאה:

==למה==
__עץ קוד תחילי אופטימלי לא מכיל קודקוד פנימי עם ילד אחד, כלומר הוא עץ שלם__ 
נניח בשלילה שלעץ תחילי אופטימלי $T$ ישנו קודקוד פנימי $k$ עם ילד אחד $x$. נזכיר רק שקודקוד פנימי לא משוייך לאף תו ולכן מחיקה שלו לא אמורה להשפיע על מספר התווים בקידוד אלא רק על אורך של קידוד כלשהו. 
לפי אלגוריתם מחיקה מעץ בינארי , זאת מחיקה די פשוטה שכל מה שהיא עושה זה להקטין את עומק הילד , במקרה הזה $x$,  ב1. נעשה זאת ונסתכל על אחד העלים ש $x$ הוא חלק מהמסלול שלו נסמנו $m$ ואת $T^{\prime}$ כעץ המתקבל מהפעולה הזאת 

$$COST(T^{\prime})= \left(\sum\limits_{\sigma\in\Sigma\text{/}m} f_{\sigma}\cdot d_{T}(\sigma)\right)+ f_{m}\cdot(d_{T}(m)-1)< \sum\limits_{\sigma\in\Sigma }f_{\sigma}\cdot d_{T}(\sigma)= COST(T)$$

__בסתירה__ לכך ש $T$ עץ קוד תחילי אופטימלי.

## בניית Huffman code
נרצה ללכת על משהו דומה לאינטואיצייה שתיארנו למעלה,  במקום לתת את המסלול הכי קצר לתווים עם תדירות נמוכה נרצה ללכת בגישה של להעניק את המסלול הכי ארוך לתווים עם התדירות הכי גבוהה. 
נראה אלגוריתם חמדן שמממש _עץ קוד תחילי אוטפימלי_ שמראה בידיוק את הנ״ל. הוכחת נכונות האלגוריתם מבוססת על התכונות של אלגוריתם חמדני שהם [[Computer Science/Algorithms/greedy algorithms#הבחירה החמדנית\|הבחירה החמדנית]] ו [[Computer Science/Algorithms/greedy algorithms#תת- המבנה האופטמימלי\|תת המבנה האופטימלי]] . נראה את הפסודו קוד ואז נסביר ונוכיח אותו
``` psudo
HUFFMAN(E)
	n = |E|
	Q = E
	for i=1 to n-1
		do allocate a new node z
			z.left = x = GET-MIN(Q)
			z.right = y = GET-MIN(Q)
			f[z]= f[x]ִ+f[y]
			INSERT(Q,z)
	return GET-MIN(Q)
```

אם $x,y$ הם התווים עם התדירות הנמוכה ביותר נגדיר $z\notin\Sigma$ כך שהוא יהיה אבא של $x,y$  בעץ עם תדירות : $f_{z}=f_{x}+f_{y}$ וכעת ממשיכים לעבוד על ה א״ב $\Sigma^{\prime}= \Sigma\cup\{z\}\text{/}\{y,x\}$ .
האלגוריתם בונה עץ חילי אופטימלי בשיטת bottom-up, כלומר קודם כל בונים את העלים ועולים למעלה לשורש. 
מתחילים בא״ב בגודל $n$ וכל פעם ממזגים באופן שתיארנו למעלה וכך מקטינים את $n$ ב אחד כל פעם עד שמגיעים לשורש. 
$Q$ זאת בעצם ערימת מינימום בינארית לפי יחס סדר על התדירויות כך שבכל איטרציה מבצעים את המיזוג המתואר למעלה ומכניסים את $z$ לערימה ובריקרוסיה הולכים ל א״ב בלי x,y אבל כם עם z . ככה מבצעים $n-1$ איטרציות עד שנשאר קודקוד אחד, השורש של העץ, הוא זה שחוזר גם בשורה האחרונה.

דוגמת הרצה עבור 
![Pasted image 20221119182301.png|300](/img/user/Assets/Pasted%20image%2020221119182301.png)

![Pasted image 20221119232410.png](/img/user/Assets/Pasted%20image%2020221119232410.png)

__זמן הריצה__ עבור $|\Sigma|=n$ קבוצת האותיות: אתחול ערימה בינארית עם $n$ קודקודים הוא ב $O(n)$ והלולאה מבוצעת $n-1$ פעמים כאשר כל פעם שולפים את שתי המינימום ב $\log n$ וסך הכל זמן הריצה יהיה $O(n\log n)$.

### הוכחת נכונות
#### תכונת הבחירה החמדנית
קודם כל נבין מהי הבחירה החמדנית שעשינו כאן, עבור א״ב $\Sigma$ בגודל לפחות 2 ולכל אות $\sigma$ מוגדרת התדירות $f_{\sigma}$ , אזי עבור $x,y\in\Sigma$ שתי האותיות עם התדירות הנמוכה ביותר __קיים__ עץ קוד תחילי אופטימלי כאשר $x,y$ הם עלים אחים והם העמוקים ביותר בעץ. 

_הוכחה_:
יהי עץ קוד תחילי אופטימלי $T$ עבור $\Sigma$ והתדירויות הנכונות. ניקח את העלה העמוק ביותר בעץ נמסנו $a$ . כיוון ש $T$ אופטימלי, לאבא של $a$ יש ילד נוסף והבן הזה חייב להיות על גם הוא (אחרת $a$ הוא לא העמוק ביותר בעץ). נסמן את האח $b$ ונשים לב שהוא גם העלה הנמוך ביותר בעץ. 
בעץ $T$ אנחנו יודעים ש  $x,y$ הם עדיין עלים איפה שהוא בעץ ויתקיים 

$$d_{T}(x)\leq d_{T}(a)\wedge d_{T}(y)\leq d_{T}(b)$$

(זה עניין סמנטי בלבד כי אנחנו ל יודעים את המיקומים של $x,y$ בעץ אלא רק שהם יותר ״גבוהים״ מהעלים הנמוכים ביותר, כמו כן האפשרות שהם שווים לא נשללת בא״שׁ הזה).
כעת נתבונן בעץ שבו מחליפים את $x$ עם $a$ ואת $y$ עם $b$ (בלי הגבלת הכלליות) ונסמן את העץ החדש $T^{\prime}$ 

![Pasted image 20221120183153.png|350](/img/user/Assets/Pasted%20image%2020221120183153.png)
כלומר 

$$\displaylines{
d_{T}(x)= d_{T^{\prime}}(a)\\
d_{T}(a)=d_{T^{\prime}}(x)\\
d_{T}(y)= d_{T^{\prime}}(b)\\
d_{T}(b)=d_{T^{\prime}}(y)\\
}$$


ולכן 

$$\displaylines{
COST(T)-COST(T^{\prime})= \sum\limits_{\sigma\in\Sigma} f_{\sigma}\cdot d_{T}(\sigma)-\sum\limits_{\sigma\in\Sigma} f_{\sigma}\cdot d_{T^{\prime}}(\sigma)\\
}$$

נשים לב שהגורמים היחידים שלא יצטצמטו הם ההחלפות שעשינו ולכן 

$$\displaylines{
=\sum\limits_{i\in \{a,b,x,y\}} f_{i}\cdot d_{T}(i) - \sum\limits_{i\in \{a,b,x,y\}}f_{i}\cdot d_{T^{\prime}}(i)=\\\\  f_{a}(d_{T}(a)-d_{T^{\prime}}(a))+f_{b}(d_{T}(b)-d_{T^{\prime}}(b))+f_{x}(d_{T}(x)-d_{T^{\prime}}(x))+f_{y}(d_{T}(y)-d_{T^{\prime}}(y))=\\ \\
f_{a}(d_{T}(a)-d_{T^{}}(x))+f_{b}(d_{T}(b)-d_{T^{}}(y))+f_{x}(d_{T}(x)-d_{T^{}}(a))+f_{y}(d_{T}(y)-d_{T^{}}(b)) = \\ \\ 
(f_{a}-f_{x})(d_{T}(a)-d_{T^{}}(x))+(f_{b}-f_{y})(d_{T}(b)-d_{T^{}}(y))
}$$

נשים לב שכל הביטויים האלה גדולים מ 0 ולכן קיבלנו שההפרשת בין העלויות של העצים גדול מ 0 כלומר העלות של $T$ גבוהה או שווה מהעלות של $T^{\prime}$ אבל $T^{\prime}$ עץ אופטימלי ולכן היא לא יכולה להיות גבוהה יותר כלומר 

$$COST(T)\geq COST(T^{\prime})\wedge COST(T)\leq COST(T^{\prime})\leftrightarrow COST(T)=COST(T^\prime)$$

כלומר גם $T$ הוא עץ אופטימלי.

#### תת המבנה האופטימלי
כעת נוכל להוכיח את התכונה השנייה של אלגוריתם חמדן. בניגוד לחיפוש בינארי, באלגוריתם הזה אנחנו צריכים לזכור את כל הבחירות החמדניות המקומיות שעשינו כדי להגיע לתוצאה כיוון שאלו בונות את העץ. אנחנו נרצה לאפיין ולהוכיח שהמבנה של האלגוריתם הוא אכן תת מבנה אופטימלי בצורה שתתאים לבחירה של  האלגוריתם ובפרט להראות שאם הריקורסיה מחזירה פתרון אופטימלי אז ״מיזוג״ הפתרון עם הבחירה החמדנית נותן פתרון אופטימלי למופע מקומי. 

יהי $\Sigma$ א״ב מגודל לפחות 2, כאשר לכל תו מוגדרת התדירות המתאימה לו. אם ניקח $x,y\in\Sigma$ שתי התווים עם התדירות הנמוכה ביותר ונגדיר איתם $z\notin\Sigma$ שיקיים 
$f_{z}=f_{x}+f_{y}$ ונבנה עץ $T^{\prime}$ אופטימלי עבור $\Sigma^{\prime}=E\cup\{z\}-\{x,y\}$ __אזי__ : העץ $T$ המתקבל מ $T^{\prime}$ על ידי הוספת $x,y$ כבנים של $z$ הוא __עץ קוד תחילי אופטימלי עבור $\Sigma$__ .

_הוכחה_ :  
נשים לב שכאן המטרה היא שונה בניגוד להוכחה של התכונה הראשונה,  אנחנו רוצים להראות כאן באופן כמעט אינדוקטיבי שהרחבת המבנה שלנו על ידי הבחירה החמדנית באופן ריקורסיבי תוביל לפתרון אופטימלי. הטענה הראשונה שהוכחנו תעזור לנו בכך כיוון שאנחנו יודעים בוודאות שקיים עץ אופטימלי שמקיים את תכונת הבחירה החמדנית __כלומר__ נוכל להניח שתת המבנה האופטימלי שלנו הוא אכן כזה.

נשים לב ש $d_{T}(x)=d_{T^{}}(y)= d_{T^{\prime}}(z)+1$ וגם $\forall_{\sigma\neq x,y\in \Sigma}: d_{T}(\sigma)=d_{T^\prime}(\sigma)$ זאת בגלל שבכלל לא נגענו בהם. סך הכל נקבל 

$$\displaylines{
COST(T)-COST(T^{\prime})= \sum\limits_{\sigma\in\Sigma} f_{\sigma}\cdot d_{T}(\sigma)-\sum\limits_{\sigma\in\Sigma} f_{\sigma}\cdot d_{T^{\prime}}(\sigma)\\
= f_{x}\cdot d_{T}(x)+ f_{y}\cdot d_{T}(y)- f_{z}\cdot d_{T^{\prime}}(z)\\
=  f_{x}\cdot d_{T}(x)+ f_{y}\cdot d_{T}(y)- (f_{x}+ f_{y})\cdot (d_{T^{}}(x)-1)\\
= f_{x}\cdot d_{T}(x)+ f_{y}\cdot d_{T}(y)- f_{x}\cdot d_{T}(x) + f_{y}- f_{x}\cdot d_{T}(x) + f_{y} = \\
f_{y}\cdot d_{T}(y)+f_{x}- f_{y}\cdot d_{T}(y)+ f_{y}= \\
f_{y}+f_{x}= f_{z}
}$$

כלומר קיבלנו 

$$COST(T)=COST(T^{\prime})+ f_{z}$$

כעת, ניקח $\overline{T}$ עץ תחילי אופטימלי עבור $\Sigma$. ע״י למת הבחירה החמדנית, נניח בלי הגבלת הכלליות ש $x,y$ אחים ב $\overline{T}$ . 
ניקח $\overline{T}^{\prime}$ עץ קוד תחילי המתקבל מ $\overline{T}$ על ידי החלפת  $x,y$ וקודקוד האבא שלהם בעלה חדש $z$ .

![Pasted image 20221127211946.png|450](/img/user/Assets/Pasted%20image%2020221127211946.png)

מההגדרה יתקיים ש $\overline{T}^{\prime}$  עץ קוד תחילי עבור $\Sigma^{\prime}$ . כמו כן, מההוכחה הקודמת ניתן לראות ש $COST(\overline{T})= COST(\overline{T}^{\prime})+ f_{z}$ . 
סך הכל מכל העצים שבנינו יתקיים 

$$COST(\overline{T})\leq COST(T)$$

אבל

$$COST(\overline{T})= COST(\overline{T}^{\prime})+f_{z} \geq COST(T^{\prime})+ f_{z} = COST(T)$$

זה נכון בגלל ש$T^{\prime}$ אופטימלי. כלומר קיבלנו שיוויון ולכן $T$ אופטימלי. מה שעשינו כאן בעצם זה השתמשנו בעץ תחילי אופטימלי שמקיים את תכונת הבחירה החמדנית והראנו שהעלות שלו שקולה לעץ שמתקבל מהבנייה הריקורסיבית שעשינו. כלומר הראנו שהצעד החמדני אכן מביא אותנו לפתרון אופטימלי באופן ריקורסיבי. השלב הראשון היה למצוא את הקשר בין העלויות, לאחר מכן הראנו שאם עושים את זה על עץ שמקיים את למת הבחירה החמדנית אז הוא עץ תחילי אופטימלי.

