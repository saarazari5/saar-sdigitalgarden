---
{"dateCreated":"2023-08-03 13:59","tags":["statistics","cs_biu"],"pageDirection":"rtl","dg-publish":true,"permalink":"/computer-science/probability/statistics/point-statistical-estimation/","dgPassFrontmatter":true}
---



# אמידה סטטיסטית נקודתית
דיברנו על הגשר מתורת ההסתברות אל ה[[Computer Science/Probability/Statistics/Statistical inference basics\|ההסקה הסטטיסטית]] .
כעת נרצה לדבר על התאוריה שמשתמשת בתורת ההסתברות כדי להסיק מסקנות לגבי האוכלוסייה מתוך התוצאות של מדגם תצפיות.
אחד הנושאים המרכזיים של הסקה סטטיסטית הוא, אמידה של מאפיינים שונים של האוכלוסייה שבוא נתעסק בסיכום זה.
## עקרונות של אמידה
במקרים רבים נרצה לדעת את ערכו של פרמטר מסוים באוכלוסייה. בגלל גודלה של האוכלוסייה איננו יכולים לחשב אותו ואנו נאלצים להתבסס על הסטטיסטי המתאים במדגם מקרי מתוך אותה אוכלוסייה. תהליך זה נקרא __אמידה__.

_דוגמה לבעיה של אמידה היא למשל , אמידה של ההסתברות להצלחה של טיפול רפואי באמצעות מדגם של חולים שיקבלו את הטיפול._

בכל בעיית אמידה נרצה לאמוד מדד מסוים של המשתנה המקרי הנבדק או של האוכלוסייה הנבדקת. מדד זה נקרא __פרמטר__.

>[!info] הגדרה
>פרמטר של פונקציית ההתפלגות של מ״מ הוא ערך הנקבע על ידי התפלגות זו, ומהווה אחד המאפיינים שלה.

הפרמטרים החשובים ביותר של מ״מ שדיברנו עליהם הינם התוחלת והשונות של משתנה מקרי: $E(X), V(X)$ .
פרמטר חשוב נוסף שנאמוד בקורס הוא הפרמטר $p$ שציין את ״ההסתברות להצלחה״.

### כיצד אומדים פרמטר?
בעזרת סטטיסטי מתאים. 
>[!info] הגדרה
>סטטיסטי הוא ביטוי מתמטי מוגדר (פונקציה) של תצפיות המדגם $X_{1},\dots,X_{n}$

נסמן ב $\theta$ את הפרמטר שיש לאמוד ואת הסטטיסטי המשמש לאמידתו $\hat\theta$ .
במקרה זה נאמר כי $\hat\theta$ __הוא אומד נקודתי__ ל $\theta$.
הכוונה היא שהערך שיקבל המשתנה המקרי $\hat\Theta$ עבור מדגם מסוים יהווה עבורנו __אומדן__ לפרמטר $\theta$ שנסמנו ב $\hat\theta$.

למשל, עבור התוחלת $\mu$ שהוא בעצם פרמטר כבר ראינו שממוצע המדגם $\overline{X}$ הוא האומד הנקודתי לתוחלת.
הערך ש $\overline{X}$ יקבל עבור מדגם מתוך אוכלוסייה בעלת תוחלת $\mu$, שאותה אנו רוצים לאמוד, יהווה אומדן ל $\mu$, במקרה זה $\theta=\mu$ . סך הכל יתקיים $\hat\Theta=\overline{X}$ ועבור המדגם המסויים $\hat\theta=\overline{x}$ .

>[!note] הבחנה
> פרמטר הוא מספר קבוע, ואילו האומד שלו $\hat\Theta$ הוא משתנה מקרי, וערכיו מהווים אומדנים לפרמטר.  

נזכיר ש __התפלגות הדגימה__ היא פונקציית ההסתברות של סטטיסטי כלשהו. גם לאומד $\hat\Theta$ יש התפלגות דגימה. 
![Screenshot 2023-08-03 at 15.15.17.png](/img/user/Assets/Screenshot%202023-08-03%20at%2015.15.17.png)
כלומר, מתוך אוכלוסייה בעלת הפרמטר $\theta$ נוציא מדגם בגודל $n$, ונחשב בו את האומד $\hat\Theta$ . אומד זה הוא מ״מ אשר יכול לקבל ערכים שונים בהסתברויות שונות (למשל, יכלנו להוציא אינסוף מדגמים בגודל $n$ ובכל אחד מהם לחשב את הממוצע, התפלגות הערכים השונים הייתה מתבטאת בהתפלגות ההסתברויות).

__שגיאת אמידה__:
כיוון שאומד הוא משתנה מקרי והוא מקבל ערכים שונים אז ברור שבניסויי דגימה שונים נוכל לקבל ערכים שונים לאומד. נגדיר __שגיאת אמידה__ להיות $\hat\theta-\theta$ כלומר ההפרש בין האומדן הנקודתי לפרמטר עצמו. 
### תכונות האמד
__א.__ __עקביות-__ ככל שהמדגם גדול יותר ההסתברות שהאמד יתכנס לפרמטר האמיתי $\hat\theta\to_{n\to\infty}\theta$ .
__ב.__ __אי הטיה-__ התוחלת של האמד שווה לפרמטר

נשים לב אלו תכונות לקביעה של אמד תקין, הם לא חייבים בהכרח להתקיים.
## אומד חסר-הטיה
ננסה לענות על השאלה: כיצד נבחר איזה סטטיסטי יש לחשב במדגם שנוציא, כדי לאמוד את הפרמטר בצורה הטובה ביותר. 

אנחנו מחפשים סטטיסטי שיקיים $E(\hat\Theta)=\theta$ .
כלומר, נחפש סטטיסטי כזה שאילו היינו מוציאים אינסוף מדגמים בגודל שהחלטנו עליו, ובכל מדגם היינו מחשבים את הסטטיסטי שבחרנו, אז ממוצע ההתפלגות של כל הערכים הללו הייתה שווה בידיוק לפרמטר.

>[!info] הגדרה
>סטטיסטי $\hat\Theta$ ייקרא __אומד חסר הטיה__ לפרמטר $\theta$ אם $E(\hat\Theta)=\theta$
אומד ייקרא מוטה אם השיוויון אינו מתקיים.

אם כן, ממוצע המדגם הוא דוגמה לאומד חסר הטיה עבור הפרמטר התוחלת.
שכן התוחלת שלו שווה בידיוק לתוחלת של הפרמטר.

במצב שבו $\hat\Theta$ הוא אומד חסר הטיה ל $\theta$ , אזי, אם נתבונן בשגיאת האמידה (שאף היא משתנה מקרי כי היא צירוף ליניארי של משתנה מקרי) נקבל כי 

$$E(\hat\Theta-\theta)=E(\hat\Theta)-\theta = \theta-\theta =0$$
כלומר התוחלת של שגיאת האמידה היא $0$.
![Screenshot 2023-08-03 at 16.12.34.png](/img/user/Assets/Screenshot%202023-08-03%20at%2016.12.34.png)
למשל , ההתפלגות הראשונה היא חסרת הטייה ביחס ל $\theta$ בעוד ההתפלגות השנייה הינה מוטה. 

## אומדים חסרי הטיה לתוחלת ושונות
## ממוצע המדגם
הראנו כבר שממוצע המדגם , ללא תלות בגודלו וללא תלות בהתפלגות של $X$ תקיים
$$E(\overline{X})=\mu=E(X)$$
כפי שכבר אמרנו, המתבקש מכך הוא שממוצע המדגם הוא אומר חסר הטיה לתוחלת $\mu$.

## אומד לשונות
ננסה לבנות אומד חסר הטיה לשונות $V(X)=\sigma^{2}$ . נזכור כי $\sigma^{2}=V(X)=E(X-\mu)^{2}$ , לכן אומד טבעי ל $\sigma^{2}$ על פי המדגם $\{X_{i}\}$ יהיה 

$$\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}$$

זה מאוד דומה ל[[Computer Science/Probability/Statistics/Descriptive statistics#שונות וסטיית תקן\|שונות המדגם]] אם כי ההבדל הוא שכאן מודדים את המרחק מהתוחלת ולא ממוצע המדגם.
נוכיח שזהו אומד חסר הטייה על ידי חישוב תוחלתו 

$$E\left(\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}\right)= \frac{1}{n}\sum\limits_{i=1}^{n}E(X_{i}-\mu)^{2}$$

לפי ההגדרה של מדגם מקרי, לכל $X_{i}$ יש את אותה ההתפלגות כמו המשתנה המקרי שממנו דוגמים $X$ ולכן 

$$=\frac{1}{n}\cdot nE[(X-\mu)^{2}]= E[(X-\mu)^{2}]=\sigma^{2}$$

ולכן הנ״ל הוא אומד חסר הטייה לשונות. 

החסרון העיקרי של אומד זה הוא התלות בתוחלת שהרבה פעמים לא ידועה לנו, לכן הפתרון הטבעי ביותר העולה על הדעת הוא להחליף את התוחלת __באומד שלו__ $\overline{X}$ ולנסות לאמוד את $\sigma^{2}$ בעזרת הביטוי $\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\overline{X})^{2}$ אך במהרה אם ננסה לחשב את התוחלת של הביטוי הזה נקבל אומד מוטה. נקבל שהתוחלת היא $(\frac{n-1}{n})\sigma^{2}$ . נוכל לתקן את האומד הזה ולהפוך אותו לחסר הטייה כך 

$$\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\overline{X})^{2}$$
באופן הזה התוחלת תהיה $\frac{1}{n-1}(n-1)\sigma^{2}=\sigma^{2}$ . 

נסמן את הביטוי הנ״ל $\hat{S^{2}}$ . בעצם זה מ״מ המקבל ערכים שונים שיסומנו $\hat{s^{2}}$. הוא מתאים לכל $n>1$ .

__ביטוי השונות עד כה:__
_א._ השונות באוכלוסייה או במ״מ (בהתפלגות הסתברותיות) היא 
$$\sigma^{2}=\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}P(x_{i})= E(X-\mu)^{2}$$
_ב._ השונו במדגם מסוים (בהתפלגות שכיחויות) היא 
$$s^{2}= \frac{1}{n}\sum\limits_{i=1}^{n}(x_{i}-\overline{x})^{2}$$

==בשני המקרים השונות היא מדד פיזור, המבוטא על ידי ממוצע ריבועי הסטיות מן הממוצע של האוכלוסייה או המדגם== 

_ג._ אומד חסר הטיה לשונות של האוכלוסייה על סמך מדגם 
$$\hat{S^{2}}= \frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\overline{X}^{})^{2}$$
_ד._ במדגם מסוים נקבל את הערך 
$$\hat{s^{2}}= \frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\overline{X})^{2}$$

__קיים כמובן קשר בין $\hat{s^{2}}$ ל $s^{2}$ והוא__ 

$$\hat{s^{2}}= \left(\frac{n}{n-1}\right)s^{2}$$

כלומר נוכל לקחת את האומדן לשונות של האוכלוסייה ולתאר איתו את מידת הפיזור של הסטטיסטי בתוך המדגם.

__המסקנה__ : ככל שהמדגם גדול יותר כך ההבדל בין האומדן לבין שונות המדגם קטנה יותר ולכן שונות המדגם מהווה אומד __כמעט__ חסר הטיה ל $\sigma^{2}$ .

## שיטות אמידה
### שיטת המומנטים
שיטת המומנטים היא שיטת אמידה לפרמטרים שמאפיינים התפלגות של אוכלוסייה מסויימת. 
נגדיר את המומנט ה$k$ באמצעות ממוצע החזקה ה$k$ של המ״מ $X$ ממנו נדגום. 

$$\displaylines{
\mu_{1}=E[X^{1}]\\ \mu_{2}=E[X^{2}]\\ \mu_{3}=E[X^{3}] \\ \vdots
}$$

נניח שיש לנו התפלגות עם פרמטרים לא ידועים $\theta_{1},\dots,\theta_{k}$ . כעת נבצע מדגם ועל סמך המומנטים של המדגם נאמוד את הפרמטרים.

בהינתן המדגם בגודל $n$ ותצפיות המדגם $x_{1},x_{2},\dots,x_{n}$ . המומנטים של המדגמים יהיו 

$$\forall_{1\leq i\leq n}:\hat\mu_{i}= \frac{\sum\limits_{j=1}^{n}x_{j}^{i}}{n}$$
__בעצם הרעיון הוא__:
1. נשווה כל מומנט מסדר $k$ לאומדן שלו במדגם.
2. נפתור מערכת של $k$ משוואות עם $k$ נעלמים עבור האומדנים כדי לקבל אומדן עבור כל פרמטר באוכלוסייה.

_חשוב לשים לב שאנחנו עושים את זה עבור מדגם בודד מגודל כלשהו_.

__למה מומנטים?__
* מומנט מסדר ראשון זוהי התוחלת: מדד למרכז ההתפלגות.
* מומנט מסדר שני מבטא שונות: מדד לפיזור סביב תוחלת ההתפלגות.
* מומנט מסדר שלישי מבטא skewness: מדד לסמטריה סביב התוחלת.
* מומנט מסדר רביעי מבטא kortosis: מדד מקובל למידת הריכוז של פונקציית צפיפות או התפלגות של משתנה מקרי ממשי.

המומנטים בעצם נותנים לנו את מידע על ההתפלגות כפי שהיינו יכולים להניח אם היה לנו את פונקציית ההסתברות מצויירת.
![Screenshot 2023-08-03 at 18.26.12.png](/img/user/Assets/Screenshot%202023-08-03%20at%2018.26.12.png)

השיטה __פשוטה__ וקלה לחישוב, אך יכולה לפעמים לתת אומדנים מוטים. בדרך כלל עדיף את שיטת הנראות המירבית עליה נדבר בהמשך.

נסתכל על הדוגמה הבאה

$$f(x)=\begin{cases}
x^{\theta-1} & x\in[0,1]\\0 & else
\end{cases}$$

נרצה למצוא אומד לפי שיטת המומנטים ל$\theta$ . נחשב תוחלת על [[Computer Science/Probability/Continuous Random Variables\|משתנה רציף]] :

$$E(x)= \int_{0}^{1}x\cdot x^{\theta-1}=\int_{0}^{1}x^{\theta}= \frac{1^{\theta+1}}{\theta+1}- \frac{0^{\theta+1}}{\theta+1}= \frac{1}{\theta+1}$$

כעת זהו ממוצע המדגם $\overline{x}= \frac{1}{\theta+1}$
נוכל אם כן להסיק ש $\hat\theta= \frac{1}{\overline{x}}-1$ . וזהו האומד ל$\theta$.

__דוגמה 2:__
בכד 100 כדורים וידוע ש $50$ מהכדורים הם בצבע כחול והשאר בצבעים שונים.
נדגמו $n$ כדורים עם החזרה ונמצא שעשרה מהם בצבע כחול. נרצה לחשב אומד על סמך שיטת המומנטים למספר הכדורים שהוציאו מהכד.

ההסתברות להוציא בצבע כדור כחול היא $p= \frac{50}{100}= \frac{1}{2}$ 
מספר הכדורים בצבע כחול $X$ זה מ״מ מתפלג בינומית $X\sim BIN(n,p)$ .
התוחלת של משתנה בינומי היא $E(X)= np$.
כלומר המומנט הראשון שהוא התוחלת יקיים שערכו הוא $\frac{n}{2}$ .
ממוצע הכדורים הכחולים במדגם שלנו הוא $10$ , נציב זאת כתוחלת ונקבל 

$$10= \frac{\hat{n}}{2}\to \hat{n}=20$$

כעת, חזרו על הניסוי פעמיים נוספות והפעם התקבלו $8$ ו $11$ כדורים, ונרצה לאמוד את מספר הכדורים שהוציאו מהכד על סמך שלושת המדגמים. נגדיר אם כן 

$$Y=X_{1}+X_{2}+X_{3}$$
מליניאריות התוחלת נקבל 

$$E[X_{1}+X_{2}+X_{3}]=E[X_{1}]+E[X_{2}]+E[X_{3}]= 3np$$

>[!info] הבחנה
>סכום של בינומי מתפלג בינומי $Y\sim BIN(3n,p)$

__דוגמה 3__:
נסתכל על התפלגות מעריכית $X\sim exp(\theta)$ . 
התוחלת שהיא המומנט מסדר ראשון שווה ל $E(X)= \frac{1}{\theta}$.
כעת נבצע מדגם $X_{i}$ כאשר $i\in[1,n]$ .
האומד לתוחלת על סמך המדגם יהיה $\hat\mu_{1}= \sum\limits_{i=1}^{n}X_{1}\cdot \frac{1}{n}$  נשווה את זה עם התוחלת ונקבל אומדן ל$\theta$ שהוא:

$$\frac{1}{\hat\theta}= \frac{\sum\limits_{i=1}^{n}x_{i}}{n}\to \hat\theta = \frac{n}{\overline{x}}$$

__דוגמה 4:__ 
נסתכל על התפלגות אחידה $X\sim U(0,b)$ 
התוחלת  היא $E(X)= \frac{0+b}{2}$  באותו אופן נוכל לקבל אומדן ל$b$ :

$$\hat b = \frac{2\overline{x}}{2}$$

נשים לב להטייה שיכולה לקרות לנו כאן, אם $X\sim U(0,5)$ עבור מדגם של 10 תצפיות: $4,0,5,3,5,4,2,4,2,1$ נקבל שהאומדן $\hat b$ יהיה $6$.

__מצב שבו יש לנו שתי נעלמים__:
![Screenshot 2023-08-03 at 19.08.41.png](/img/user/Assets/Screenshot%202023-08-03%20at%2019.08.41.png)

## אמד נראות מקסימלית
בהינתן פרמטר לא ידוע $\theta$ משתנה מקרי $X$ ופונקציית הסתברות התלויה ב $X,\theta$ : $f(X,\theta)$.

נבצע מדגם בגודל $n$: $X_{1},X_{2},\dots,X_{n}$ 
אומד נראות מקסימלית $\hat\theta$ יהיה הערך של $\theta$ מבין כל הערכים האפשריים כך שההסתברות הגבוהה ביותר שנקבל את המדגם שלנו.

פונקציית הנראות תהיה 

$$L(\theta)=\prod_{i=1}^{n}f(X_{i},n)$$

נמצא את הערף $\theta$ שמביא את הפונקצייה לערך מקסימלי.
כדי לקבל את הערך המקסימלי נוכל לגזור ולהשוות ל $0$ ולוודא מקסימליות עם בדיקה עבור הנגזרת השנייה כלומר

$$L^{\prime}(\theta)=0\wedge L^{\prime\prime }(\theta)<0$$
>[!info] אינטואיצייה
>באופן אינטואיטיבי הגישה אומרת שכדי לנבא היטב את הפרמטר האמיתי על-סמך מדגם מקרי מסוים, יש לבדוק איזה פרמטר מתוך כל האפשרויות הוא זה ש"יסביר" בצורה הטובה ביותר את המדגם. כלומר אומד הנראות המרבית הוא הפרמטר שאילו היינו מציבים בפונקציית ההתפלגות מראש, הוא היה נותן את ההסתברות הגבוהה ביותר לקבל את המדגם שאכן התקבל

__דוגמה 1__:
ישנם 3 כדים עם כדורים כחולים וסגולים.
![Screenshot 2023-08-03 at 19.26.07.png](/img/user/Assets/Screenshot%202023-08-03%20at%2019.26.07.png)
בחרנו באופן מקרי כד והוצאנו ממנו 3 כדורים ללא החזרה, בנה אומדן נראות מקסימלית לכד הנבחר, אם הכדור הראשון ושני יצאו כחולים, והשלישי סגול.

נחשב את ההסתברות לקבל את התוצאה הרצויה בכל כד:
__כד א:__ 
$$\frac{3}{5}\cdot \frac{2}{4}\cdot \frac{2}{3}= 0.2$$
__כד ב:__
$$\frac{4}{5}\cdot \frac{3}{4}\cdot \frac{1}{3}= 0.2$$
__כד ג:__
$0$ כי אין כדורים סגולים.

בעצם נרצה את ההסתברות המקסימלית מבין הכדים שזה אומר ש אנ״מ - כד א׳ או כד ב׳.
כאשר אין תלות באיזשהו פרמטר פשוט ניקח את ההסתברות המקסימלית בהתפלגות.

__דוגמה 2__:
מספרי קלפי $V_{max}$ בחבילת קלפים של פוקימון מתפלג לפי ההתפלגות הבאה:
![Screenshot 2023-08-03 at 19.33.11.png](/img/user/Assets/Screenshot%202023-08-03%20at%2019.33.11.png)
המספר קלפים יכול להיות $\{1,2,3\}$ וההסתברויות תלויות ב $\theta$.

נרצה למצוא אומדן נראות מקסימלית ל $\theta$ על סמך מדגם מקרי של 3 חבילות 
$x_{1}=1,x_{2}=2,x_{3}=1$ .

נרשום את פונקציית הנראות 

$$L(\theta)=f(x_{1},\theta)f(x_{2},\theta)f(x_{3},\theta)=\theta(1-3\theta)\theta=\theta^{2}-3\theta^{3}$$

נגזור ונשווה ל$0$: 
$$L^{\prime}= 2\theta-9\theta^{2}=\theta(2-9\theta)$$

כמובן ש $\theta$ לא יכול להיות $0$ ולכן $\theta= \frac{2}{9}=0.222$ . נבדוק את הנגזרת השנייה כדי לוודא מקסימום

$$L^{\prime\prime}(\theta)= 2-18\theta\to 2-18\cdot \frac{2}{9}=-3.33$$

ולכן זאת נקודת מקסימום.

![Screenshot 2023-08-03 at 19.42.09.png](/img/user/Assets/Screenshot%202023-08-03%20at%2019.42.09.png)

>[!info] תכונה
>אם $\hat\theta$ אנ״מ ל$\theta$ אזי פונקצייה $f$ ח״ע של $\hat\theta$ תהיה אנ״מ ל $f(\theta)$

למשל, אם נרצה את אומדן נראות מקסימלית לקבל 3 קלפים. כלומר ל $2\theta$ .
מהתכונה הנ״ל אנחנו יודעים ש $f(\hat\theta)=2\hat\theta$ היא ח״ע ולכן האנ״מ יהיה $2\cdot \frac{2}{9}=\frac{4}{9}$ .

__דוגמה 3:__
נתונה פונקציית הצפיפות הבאה, מצא אנ״מ על סמך 10 תצפיות ב״ת

$$f(x)=\begin{cases}
\frac{1}{\theta} & x\in(0,\theta]\\0 & else
\end{cases}$$
המכפלה תהיה 
$$L(\theta)= \frac{1}{\theta^{n}}$$
מתקיים שככל שערכה של $\theta$ קטן יותר אז הפונקצייה גדולה יותר ולכן נבחר בערך הקטן ביותר האפשרי לפי תוצאות המדגם $\hat\theta=\max(x_{i})$ .

__דוגמה 4:__
זמן ההמתנה בדקות לנציג מתפלג מעריכית עם פרמטר $\lambda$ נרצה למצוא אנ״מ להסתברות ששלושה לקוחות יחכו כל אחד מהם פחות מ5 דקות תחת הנחת אי תלות.

$$f(x)=\begin{cases}
\lambda e^{-\lambda x} & x\geq 0\\0 & else
\end{cases}$$
$$F(x)=\begin{cases}
1-e^{-\lambda x} & x\geq 0\\ 0  & else
\end{cases}$$
נצטרף גם $P(X\geq 5)= F(X=5)= 1-e^{-\lambda 5}$
פונקציית המכפלה תהיה 

$$L(\lambda)=\lambda^{3}e^{-\lambda\sum\limits x_{i}}$$
__למקסם פונקציה שקול ללמקסם את הln__ ולכן :
$$\ln L(\lambda)=3\ln(\lambda)-\lambda\sum\limits x_{i}$$
מכאן כבר לא בעיה לגזור... 

__דוגמה 5:__
נניח הטלת מטבע מזויף אשר בו בהסתברות $p=0.7$ נקבל עץ.
מה ההסתברות לקבל $7$ פעמים עץ במדגם בגודל $10$.
התפלגות הטלת המטבע היא בינומית $BIN(0.7,10)$ אנחנו יודעים שפונקציית ההסתברות של משתנה מתפלג בינומית היא 

$$P(X=k)=\binom{n}{k}p^{k}(1-p)^{n-k}$$
לרוב היינו רוצים לחשב את ההסתברות ולכן הנעלם היה $k$ . כעת אנחנו רוצים לאמוד את ההסתברות, נרצה למצוא את $p$ . פונקציית המכפלה במקרה הזה שקולה לפונקצייה ההסתברות $L(p)=P(X=k)$ רק שמתייחסים לנעלם כ $p$ ולא ל $k$.

גם כאן נוכל להשתמש בפונקציית ה$ln$ ולקבל את האומדן להסתברות $\hat{p}=\frac{k}{n}$ . הרעיון הוא שבעצם האומדן נותן לנו הסתברות למטבע שבקירוב טוב התנהגות המטבע ״באוכלוסייה״ עם ההסתברות הזאת תיתן מדגם כמו שלנו.

__לסיכום:__
![Screenshot 2023-08-03 at 20.31.07.png](/img/user/Assets/Screenshot%202023-08-03%20at%2020.31.07.png)

__משפט:__
האנ״מ לתוחלת יהיה ממוצע המדגם.
האנ״מ לשונות תהיה השונות במדגם _הוא מעט מוטה כפי שכבר הראנו והוא לא האומדן חסר הטייה שבו מחלקים ב $n-1$_ .  $\hat{S^{2}}= \frac{\sum\limits(x_{i}-\overline{x})^{2}}{n}$

## יעילות של אמדים
 כאשר יש לי $\Theta_{1}$ ו $\Theta_{2}$ אמדים חסרי הטיה עבור $\theta$ נעדיף את האמד בעל __השונות הקטנה ביותר__ .
 ![Screenshot 2023-08-04 at 12.04.17.png|400](/img/user/Assets/Screenshot%202023-08-04%20at%2012.04.17.png)
### MSE
במקרה הכללי של הנ״ל במצב שבוא האמדים אינם חסרי הטיה, נרצה לחשב את 

$$MSE(\hat\Theta)=  \frac{1}{n}\sum\limits_{i=1}^{n}(\hat\theta_{i}-\theta)^{2}= E[\ (\hat\Theta-\theta)^{2}\ ]$$

## אמידה סטטיסטית עבור קשר בין 2 משתנים
נניח שיש לנו שני משתנים מקריים $X,Y$ שיש בינהם קשר ליניארי כלומר 

$$Y=aX+b$$

נשאלת השאלה איך בוחרים קו מגמה?
נזכיר שקו מגמה הוא האומד את הקשר בין שני המשתנים האלה למרות שלפי [[Computer Science/Probability/Statistics/Descriptive statistics#מדדי פיזור\|מקדם המתאם של פירסון]] יש בינהם קשר ליניארי שאינו חזק בהכרח.

__האינטואיצייה__ תהיה לבחור גרף ישר שהכי קרוב לנקודות בדיאגרמה לשם כך נשתמש ב __אמד ריבועים פחותים__. בעצם אנחנו רוצים __לאמוד__ את הקשר הליניארי הנ״ל 

$$\hat{Y}=\hat{a}X+\hat{b}$$


![Screenshot 2023-08-04 at 12.22.55.png|350](/img/user/Assets/Screenshot%202023-08-04%20at%2012.22.55.png)
אם כן, העקרון הריבועים הפחותים מבקש שנבחר את הישר שיקיים :
א. $\sum\limits_{i=1}^{n}e_{i}=0$
ב. $\min\left(\sum\limits_{i=1}^{n}e_{i}^{2}\right)$ כלומר סכום ריבועי הסטיות מינימלי.

כדי לחשב את הקו השיקיים את הנ״ל:
__שיפוע הקו:__
$$\hat{a}= \frac{\sum\limits(x-\overline{x})(y-\overline{y})}{\sum\limits(x-\overline{x})^{2}}$$

__החותך:__
$$\hat{b}=\overline{y}-a\overline{x}$$

נוכל לחשב גם בדרך נוספת:

$$a= r \frac{S_{y}}{S_{x}}$$

כלומר מקדם המתאם כפול סטיית התקן של $y$ חלקי סטיית התקן של $x$

דרך נוספת:

$$a= \frac{cov(x,y)}{S_{x}^{2}}$$

וגם 

$$a= \frac{\sum\limits xy - n\overline{x}\cdot\overline{y} }{\sum\limits x^{2}- n\overline{x}^{2}}$$

__טיב הקו, איכות ההסבר__:
ברגרסיה אנחנו מדברים על להסביר את $Y$ על ידי $X$ . יותר נוכן לומר שאנחנו מדברים על להסביר את השונות של $Y$ עם השונות של $X$ 

![Screenshot 2023-08-04 at 12.32.06.png|359](/img/user/Assets/Screenshot%202023-08-04%20at%2012.32.06.png)
כדי להסביר נרצה לחשב את אורך הכו הכחול. שבודק את השונות של ערך האומדן $\hat{y}$ מהממוצע. ונרצה את החלק האדום שהוא בעצם $e$ ובמילים אחרות את השונות של $e$, זאת נקראת השונות הלא מוסברת על ידי קו הרגרסייה.

![Screenshot 2023-08-04 at 12.32.48.png|250](/img/user/Assets/Screenshot%202023-08-04%20at%2012.32.48.png)
![Screenshot 2023-08-04 at 12.33.18.png](/img/user/Assets/Screenshot%202023-08-04%20at%2012.33.18.png)

כעת נגדיר את אחוז השונות המוסברת להיות על ידי 

$$R^{2}= \frac{S_{\hat{y}}^{2}}{S_{y}^{2}}= r^{2}$$
_לא אוכיח את המעבר האחרון_

